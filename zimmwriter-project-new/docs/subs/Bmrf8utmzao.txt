# Web Scraping Basics In ZimmWriter

hey if you have not heard zimriter the AI writing software is now able to summarize and scrape data from the internet you can bring that data that real-time data in whether it's recent news article or product information from Amazon or some kind of big retailer or manufacturer you can bring that data in summarize it using AI all automatically and it's pretty amazing in this video I'm going to share with you how to do that where you can do that and also give you some best practices so let's dive in and get started first place that you can scrape data is inside of a magic command we'll show you that first and then the other place is inside of the SEO blog writer inside of the global background and also in the local backgrounds for your different subheadings so we'll look at the magic commands first and then we'll look at the SEO blog writer so I have notepad open we're going to work inside of here and there's this URL for the CNN article so I'm going to take this URL and I'm going to paste it in here now normally for a magic man you have to tell the AI to do something so let's say write a social media post about this URL now I'm using the word URL right here because what's happened is zimwriter let me actually run this right now and then I'll talk zenwriter is going to go out to the internet and scrape this right now and summarize it and then feed that into like background information for this particular Command right here so if you want to refer to the scraped information the data from the URL that was scraped and summarized refer to it as URL you don't paste the URL down here but say write a social media post about this URL or write a summary of this URL or write some talking points about this URL and you'll get good results from that so the scraping is almost done right now and what happens is it's going to script the URL first and then it will process our magic command all right the URL is now 100 scraped 100 summarized and now it's carrying out this magic command so write a social media post about this URL heading to Italy this summer make sure to check out fru frulia Venice Venezia man this is like really hard to say I can't say that in the Northeast not only is this region rich in culture history and stunning and natural beauty but you can also receive up to 350 pounds in vouchers to enjoy many attractions restaurants and hotels don't miss out that's pretty cool all right we just summarize this entire page with AI and then we wrote a social media post about it now I'm going to share with you a secret right now we can't see the summary that the AI made on the page so if we wanted to for example tweak this magic command write a Facebook post about this URL we'd highlight it hit control one zimrator would go and scrape this data again we don't really want that we because it's we've already scraped it we've already summarized it but we don't see that summary so what we can do is actually I can hit control V and paste the summary which is stored in the clipboard into notepad right here so when you scrape a page and you issue a magic command with the URL it's going to carry out that magic command but then also store that summary in the clipboard so what's really neat is now we can take this command write a Facebook post it at the end of the summary highlight that command and highlight the summary and hit control 1. and Now zimwriter does not have to rescrape the page it's just going to process our background information check out this amazing new initiative in Italy visitors can receive up to 350 pounds in vouchers to spend in hotels etc etc so that's a quick and easy way to repurpose the summary without having to scrape it again now if you don't want to carry out a magic command so we this was our magic Command right here this was the URL we wanted it to process if we don't want it to do that what we can do is go up here and type in summarize and then an equal sign and then if we do that and highlight it in control one zimwriter will just scrape and summarize the page and spit out the summary for us it will not process a further magic command for us so there's a couple different ways that you can go about working with URLs inside of a magic command while this is working let me give you a couple more best practices with this number one all of the scraping and summarizing whether you're doing it on Magic command or you're doing it in the SEO blog writer all uses turbo so on average if you were to scrape and summarize a 10 000 word blog post it would cost you roughly two pennies if you were to scrape and summarize a 1 000 word blog post it would probably cost you uh what a fifth of a penny so cut a penny and five pieces a fifth of a penny so it's a very economical approach to processing data I wouldn't really worry about spending too much money scraping it's all going to be very inexpensive using Turbo another best practice is right now with magic commands you can only do one URL at a time you can't paste two URLs and ask the AI to compare for instance two products at two different URLs it can't do that it's one URL at a time so here's the summary it didn't like I said it didn't carry out a magic command it just gave us that summary because we tagged this URL with summarize and then an equal sign pretty easy one last tip all of you all of the URLs that you add in have to be like HTTP or https colon forward slash and then the URL if you try some other format just www it's not going to work you need this https and whatnot and then finally sometimes the scrape won't work sometimes you might get an error message try the scrape one more time and see if it works if it doesn't work then maybe the URL is incompatible or something sometimes also it can't find any data to scrape could just be because of a glitch or whatnot scraping is not perfect it's a when you actually look at the page source here's all of the data that the AI is looking at when it's analyzing this page and it's having to parse out the actual text from all of this HTML code so it's not simple it's a very complex process scraping data is not simple at all so there are going to be some glitches here or there and that's just a nature of the Beast that we're dealing with but for the most part 99 of all the websites that you deal with should scrape just fine let's do one more this is from backlink o called reverse Outreach let's use this inside of the SEO blog writer so we'll open up the SEO blog writer now you can put URLs inside of the global background and you can also put URLs inside of your subheading background so this is like an H2 we could put a URL inside of here we're going to talk about the global background first why you would want to put something in the global background is multiple reasons number one if you use option three it can help generate your H2S using that that Global background using that scraped URL data in addition when you put a URL in here and it scrapes it and converts it to Google background that information will then be fed into each H2 each H3 each H4 as the AI writes the article and that can influence what's written so if you're writing about a very Niche subject that Global background can really help the AI understand what that what that product or that manufacturer whatever that Niche is that it does not have knowledge on though I'll have another video on understanding the global background in the background sections this is this video is more about scraping data so we're going to put our URL in here oops that's not the URL let's try again backlinko and we'll actually try to replicate this page how to get backlinks using reverse Outreach so there's techniques called reverse Outreach that's the URL we're going to scrape I can just press option three and it will scrape this URL create our summary inside of the global background and then automatically start writing those H tubes so I'm going to try that right now and you'll see a little box that will appear down here it will tell you the status of the scrape what's going to happen is zimrider will go to this URL and it will find all the data and then it will chunk it up into manageable chunks to feed open Ai and then get a summary of each of those chunks and then it will feed each of those summarized chunks back into open Ai and get one final summary out of it and it will paste that summary into this Global background section and then it will generate those H2 so there's a lot of steps involved behind the scenes in getting those H2S generated based on this particular article but this is actually really useful to replicate either a niche that the AI does not know about or repurpose someone else's article to be your own in your own style now while this is working let me mention one more thing what we could have done is we could have just taken all this text from this article copied all the text and just paste it into the global background section one of the downsides is the global background is limited to about 1 000 to 1200 words and by scraping a URL the zimwriter is going to summarize that the content on that page so it's not going to take every little last word so you are limited on the number of words you can put in the global background so using the scraping functionality can condense and capture that main point of the main sub points of that article very concisely all right the scraping has gotten to 80 and I think that's the indicator that now everything's been scraped everything's been summarized and now it's summarizing those mini chunks those mini summaries so it just should take a moment more all right so it's done right now we have overview strategy benefits implementation steps success factors feedback and testing now you'll look up here is the entire summary of that web page I recommend going through here for some things you scrape and reviewing it all right that's number one best practice don't just rely on the AI to identify what the key points are go through it and check especially if you're doing like a product Roundup and I'm going to put a little caveat right here Amazon is pretty safe all right you don't have to worry too much about Amazon and we'll talk about that in a moment but if you're scraping stuff from some other big box stores like Best Buy or Home Depot or something like that where there is a lot of other information on the page unrelated to the main topic so taking a product for instance you go to Home Depot and you're looking at a particular drill all right they might have other related drills on the same page the AI is not going to know what's about that drill and what's about the other drills and so you could get a lot of biased stuff in here so I highly recommend going through the scraped result and then editing out things that are not relevant because that is going to affect all right not only the H2 Generations if you're using option three but the actual output because this Global background is fed into each whenever the exam writer starts writing this particular H2 it's going to be fed into the content as it's writing that it's going to be fed into this H2 as it writing the content for this one make sure that this is clean and has stuff that's just relevant for how to get backlinks using reverse Outreach initially this looks pretty good right here now again this video is about scraping it's not necessarily about the global background but I'll mention this right here when you're using a global background I don't recommend going over five subheadings all right you go over five subheadings and you might get some repetition if you're going to have a lot of subheadings then I highly recommend not necessarily using a global background or at least using a global background in it in conjunction with a local background like a background for your particular H2 we're not going over five and this summary looks pretty decent this topic is not too Niche so I think the AI will be able to do a good job writing about this but if your topic is very Niche specific the AI doesn't happen to know a lot about it you have a lot of H2S a lot of h3s a lot of h4s then don't just use that Global background also use some some background for each one of these particular H2S to get better results to avoid repetition and things like that I'll have another video on best practices for background sections but that's just like a just an overview of best practices let's add one more URL in here to scrape and see how that works right now feedback and testing let's add another H2 and we'll call this I don't know what can we let's see here how to get more backlinks let's just add something that we can find out here on the internet there we go so this is perfect so we'll say other tricks and I'll take this URL and I'll copy it and I'll paste it right here and then what we'll do is we'll scrape this result and we'll review the result before we start generating the article now I mentioned before the limit for the number of words for a summary right not the input words that the AI is going to scrape but the summary that it's going to create is about 1 1000 to 1200 words inside the global background so in some instances you can paste up to three URLs inside of here for these subheading backgrounds you're limited to 500 Words so we're cutting that in half because it's all fed into open AI together you're going to be limited to the number of words we can feed into open AI so I've capped this at about 500 Words so hopefully we'll get about a 500 word summary from this so this article and what I want to do is I want to scrape that in preview it there's a couple options down here if I click this scrape URLs and start SEO writer Zoom writer will try to scrape all the urls above here and then it will start writing so I will not have an opportunity to review the scrape data I don't recommend that this option is just going to scrape those URLs and it won't start writing the article it will allow me to preview the result this button right here will allow me to start the SEO writer without scraping any URLs some people have told me that they like putting URLs in here in the background section in hopes that the AI will use those URLs as citations or links or something like that so that option is in here so I want to click this button right here to allow Zoom writer to start scraping that URL but not start writing the article we'll be able to review that scraped result and then edit it if you if we see anything that doesn't belong in there before we start writing the article I'll just Speed the video up and we'll look at the result the scrape in summary is done let's scroll up so we can check it out so it's all inside of this box at least 500 words are we can see it cut off right here building our e so it stopped right there so here it actually let's copy it from here and paste it into notepad and check it out it's easier to view when it's out of here so strategies for building white hat backlinks guest blogging partnering with businesses asking for backlinks this is great I think the AI would really go to town with this and some some good stuff for this other tricks section facts and statistics and key points that's great all right we'll just leave this as is in here it looks great it doesn't look like there's any extraneous information in here and we will go over here and specify the settings that we want to use to write this article we're going to do a short length I want second person with you we'll do literary devices I'll have lists enabled and audience personality will leave that blank we don't need any product layout prompt we're not using that I'm going to turn auto Style on it will find the most trusted person to write this article we're not going to use automatic keywords and we're going to write this using turbo and the reason I'm recommending using turbo anytime you use Global background is because the cost can get a little high if you're using like gpt4 or DaVinci and some people aren't aware of that so I highly recommend using turbo unless you're perfectly okay with the costs I think I I generated 60 subheadings an article with 60 subheadings I use DaVinci it was five dollars all right very expensive if I would have used gpt4 I think it would have been 15 so just be careful if you start using a global background people think it's a Magic Bullet but it does come with some trade-offs so we'll use turbo and there's no more URLs to scrape so I can either click this button because there's nothing to scrape and it will start writing or I can just click Start writer without scraping we'll just click this one and we'll see the little progress bar in the lower right just takes a second because it's processing that little background right now there we go I'll Speed the video up and we'll come back and check out the result the article is finished let's actually go into our directory and find it let's delete these old articles this is how to get backlinks using reverse Outreach let me drop it in this markdown converter so I want to convert it to a word doc and we'll open it up and check it out I'll make this file available in the description for this video too so you can check this out at your leisure so this was three pennies if this was not using turbo this would be 30 cents I think with DaVinci so this was three pennies using turbo and we only have five H2 or six H2S right so how to get backlinks using reverse Outreach have you ever struggled with backlinks for your website despite putting off the effort to create high quality content you still find yourself falling behind your competitors all this stuff so overview strategy benefits implementation steps start by finding journalistic keywords related to your Niche and creating content around those keywords with unique data and stats I've actually read this article it's a really good article too and that's what it talks about make sure to includes subheadings optimize around journalistic keywords and provide short answers to questions related to those keywords this is great it's actually using that background if you're wondering how others have responded to reverse Outreach strategy and are curious about testing it yourself the feedback from others suggests that it's useful in effective approach because what it actually did there's actually comments on this blog post so it scraped those and added those to the summary so many have found success with the strategy even without existing Authority and brand recognition however it's important to know that the process can take time to pick up traction it can take three to four months for your page to start to rank it can take three to four months so it's using that data it's using that summary from the article that's awesome so this is that other that section that we used and we scraped that other page from this search engine Journal discover additional tactics so I'd probably modify this and say here are some additional tactics for building white hat backlinks and improving your website search engine ranking in addition to reverse Outreach that's really cool it's tying that in there are other tricks that you can use to attract high quality backlinks here are some options create shareable content use social media engage in broken link building participate in online communities see how cool that is you're meshing together different articles different concepts I want to show you one more thing now we're going to scrape Amazon and this is important to demonstrate so let's go back to our SEO blog writer I'm going to scroll down and erase all of these settings to start fresh now I want to put a title in here best robot lawn mower and we're going to write one more blog post and this is just going to be a demonstration blog post this is not how I would write an article about best robot lawnmower I just want to demonstrate something we're going to enable the subheading background and I'm going to go to Amazon and this is where we're going to talk about IP addresses for a moment all of this scraping right now is done using your own IP address so I'm in Ohio most places don't block IP addresses from Ohio so I can happily go out to backlink oh I can go out to search engine Journal scrape their a particular page I'm not hammering their website I just make one request to their website they're not going to block my IP address I can't do that with Amazon I can't do that with Google if I want to go scrape Google I need something additional I need a rotating IP proxy a scraping proxy and and if you're in a different country if you're in China or somewhere with a firewall you might not be able to naturally just scrape these URLs without a rotating proxy also this is different than if you're using a VPN on your computer you might have a paid VPN plan that's not good enough inside of the options menu you'll see two links now one's called set a new scrape out API key and buy a scrape out API key you click this link and make sure to click this link because it will give you special price sing on this API for this rotating proxy you'll see a little referral up here in the URL I make no money from this this is not a money maker for me at all I've negotiated with this company to give Zim writers a special price if you don't click this link right here you won't see this special pricing so for this is a special just for Zim writers in this hobby plan too for five dollars a month you can get 10 000 credits each credit is like one scrape okay so you could theoretically scrape Amazon 10 000 times in one month no one's gonna do that Google when I Implement that it's not implemented yet it might be a little bit more credits than one scrape per credit I don't know we'll figure all that out but most people can get by with the five dollar a month plan you start the free trial with this link you eventually upgrade to the five dollar plan you come in here you set the scrape owl API key when you do that you will now be able to scrape Amazon using zimwriter now what's really cool about using this is if you go to an Amazon page there's a lot of stuff on here a lot of stuff that's not relevant to this product so there's frequently bought together here are some other things in here if I just had zimwriter go to this page try to go to this page and scrape it I would get a lot of extraneous information but scrape out allows us to do some really amazing things with this and just pull out the day data related to this particular product so what we're going to do is I'm going to put in let's go to our SEO writer I'm going to put in this URL and we'll paste it right in here to the background information and we'll call this the Husqvarna Automotive robotic lawnmower that will be our title and I'm going to trigger this product layout all this is explained in the training details on my you go over here you click on online help there's an exhaustive training on using SEO blog writer so we're not explaining this stuff in this video the long and short is we're putting the URL for Amazon right here and now I want to go to another site I want to go to Home Depot and I want to demonstrate something we're going to scrape a page from Home Depot also and we're going to put this yard force in so I'll copy this I'll put yardforce right here yard for let's call it yard Force robot lawn mower that will trigger product layout on here and I will go down here and I'm I don't want to run the creation of the article I just want to process those URLs so I'm going to click this button right here scrape the URLs only and it's going to scrape those right now I'm going to talk about something I'm trying to demonstrate something to you I want to demonstrate how with so we don't need scrape out a scrape Home Depot but because we're using scrape out of scrape Amazon I've programmed it just to extract the product specific things and if you're more Technical and technologically savvy I'll explain how that works I found the corresponding CSS classes and IDs for some of these different things scrape aloe lets you to extract just data associated with a specific ID or a specific class for CSS and that allows us to get very specific with what we're scraping from the page almost no other scrapers allow you to do that we're not even touching this information right here we're not touching I believe this information right here we're just pulling the relevant things and we're also pulling the product reviews for Home Depot we're not doing that we're pulling everything on this page so if you happen to be scraping non-amazon Pages your mileage is definitely going to vary and you're going to want to review those scripts review those summary because you're going to have some of that extraneous information what I'd like to do is build functionality for users people just like you to if you are a little bit technologically savvy identify what CSS tags classes and ideas you want scraped for a particular website so imagine a community of Zim writers and you're like hey what's what's the relevant stuff for scraping a Home Depot page and somebody will share those CSS IDs and classes you can input those into Zim writer and then it will pull just the product details just the title of the product just the price and just the good stuff and discount the rest of the stuff on here I think that'd be very valuable for affiliate marketers we don't have that functionality yet I haven't built that in yet but that's where I see it going so scrape out will become even more useful as time goes on it was almost done with our scrape let me pull up notepad so we can more easily review this and I'll delete this summary and here we don't need that anymore the two URLs are summarized and again because we clicked this button it did not start writing the article which is good we want to review those summaries now like I said I explained that stuff with the special Amazon treatment using the CSS IDs and classes that allows us to have a very good quality scrape right here product name and then these are the details on it suitable for medium to large yards here's some more specifications and then here are some things from the reviews it's a bit expensive but worth the investment equipped with Theft Protection features absolutely phenomenal we don't find anything on here that's extraneous that's irrelevant maybe the rank of best seller rank is not really relevant but aside from that very good quality summary of this particular product now let's look at the Home Depot one so I'll select it all we'll bring it in here so let's go back to the product page right here so this is the yard Force it says nx100i is that what this is called Product detailed I would assume so yep nx100i controlled by a phone app Rain sensors we have the battery seven inch yep the same one doing good so far so a lot of it looks good now let's look at the bottom down here so sign up for emails and get five dollars off we don't need that Home Depot is a basically a copyright we don't need that using this site so terms and use we don't need that prices will vary here's a phone number we don't need any of this stuff so we can delete that stuff special financing we don't need that that doesn't deal with the product itself so it's impossible without identifying the various CSS uh IDs and classes to get a perfect summary out of this and this is just home people imagine if we have Best Buy we have Lowe's you have all these and that's just in the US I don't know what other stores overseas you guys have in Europe and whatnot but that's the gist of it so you should definitely go through and review your summaries if you're if you're using the SEO blog writer and you're summarizing stuff that means you want a good quality article you're still saving a lot of time this is a lot faster than doing it by hand but it's not foolproof you are going to have to review some of the stuff so we edited the summary I'm going to take it and paste it back in here and that is our new summary and now we'll go over here and we'll just write this article really quick I'll show you how it works we'll use um we can use DaVinci because we're not using a global background you'll save a lot of money by just using these local backgrounds where appropriate or triggering the product layout and that's all we want so we'll write this right now it's going to go quick again this would not be how I would write a product Roundup because our only H2S are these two different products but this will give you an idea for the type of output you can get when you trigger that product layout when you put that background information in I will also make this file available for download in the link to the description for this video the article is done and again this is this article is not representative of how I would do a product Roundup review I just wanted to demonstrate how we can scrape the URLs use those subheading backgrounds to then have the AI write about that topic let's see in here this cost 10 cents for these two H2S so remember we tagged the product layout so Husqvarna Automotive for 30 HX it's an ideal choice for those looking for a reliable automated lawn maintenance solution with GPS assisted navigation instead of our technology this robotic lawnmower is suitable for medium to large yards up to 0.8 Acres man this is really nice it's pulling it all from this specifications in here it's equipped GPS theft tracking built-in alarm system and pin code lock for security so we can probably search for it in here pin code there you go pin code lock the cutting width is 9.45 inches with an area capacity of 1430 so here's the specs here's the pros and here's the cons usually this stuff is pulled from the reviews but what else it works with GPS navigation a bit expensive let's search for that so it's although it's more expensive so yeah that's absolutely fantastic here's the yard Force so again yard Force we did the review from Home Depot not from Amazon let's see what we got yard forces robot mower keeps your lawn looking neat with its three blade cutting head and eight rear wheels and nearly silent operation this robot lawnmower is controlled by phone app and includes rain sensors rain sensors really that's cool yeah rain sensors notify the motor to return to its charging station once it recognizes the need to do that's pretty cool ultrasonic sensors lithium battery you can mow a third of an acre includes five preset cutting Heights and a mulch system let's search for that mulch built-in mulch system there you go product specs Pros cons so that's awesome imagine again you extrapolate this out you have six products and then you have a buying guide at the end your factors to consider when buying a robot lawnmower and you have five different h3s inside of their very easy to quickly build out a very comprehensive article we use DaVinci for this if you had used turbo for this instead of being nine pennies this would be one penny so I highly recommend again using turbo you'll get great results inside of Zoom writer for it and you also have that midjury prompt robot mowing a lush green lawn with a peaceful background of trees in a bright blue sky fantastic so hope you like this video I hope this kind of comprehensively covered how you can use the scraping functionality in zimwriter right now inside of the magic commands inside of the SEO blog writer I will eventually build up more functionality to get more use out of this but this so there's a lot of things you can do with it now a lot of power I'd love to hear how you're using it drop a comment down below if you did like the video please give it a thumbs up please subscribe finally there's a link to Zim writer in the description below and join the Facebook group there's over 7 000 amazing people in there that will help you in your AI Journey help you in your content creation Journey we'd all love to see you there so until next time good luck with your content generation I'll talk to you later
